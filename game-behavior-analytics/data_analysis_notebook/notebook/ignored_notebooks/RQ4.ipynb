{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588da484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RQ3: HOW DO INTERVENTIONS REDUCE CHEATING WITHOUT HARMING PERFORMANCE AND EXPERIENCE?\n",
      "SYSTEMATIC ANALYSIS OF PSYCHOLOGICAL MECHANISMS\n",
      "================================================================================\n",
      "Sample size: 1232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 0. SETUP AND DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "import sys, os, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('game-behavior-analytics/data_analysis_notebook/')\n",
    "sys.path.append(os.path.abspath('utils'))\n",
    "\n",
    "from data_utils import load_and_prepare_data\n",
    "from metadata import theory_order, theory_map\n",
    "\n",
    "df, concepts = load_and_prepare_data(\"../data/final_dataset.csv\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RQ3: HOW DO INTERVENTIONS REDUCE CHEATING WITHOUT HARMING PERFORMANCE AND EXPERIENCE?\")\n",
    "print(\"SYSTEMATIC ANALYSIS OF PSYCHOLOGICAL MECHANISMS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Sample size: {len(df)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34940531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DATA TYPE CLASSIFICATION\n",
      "----------------------------------------\n",
      "Ordinal: ['cheating_behavior']\n",
      "Categorical: ['concept']\n",
      "Continuous: 22 variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. DATA TYPE CLASSIFICATION AND PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"1. DATA TYPE CLASSIFICATION\\n\" + \"-\"*40)\n",
    "\n",
    "# Rename variables for clarity\n",
    "mechanism_renames = {\n",
    "    'descriptive_norms': 'perceived_descriptive_norms',\n",
    "    'injunctive_norms': 'perceived_injunctive_norms',\n",
    "    'reference_group_identification': 'perceived_group_identification',\n",
    "    'social_sanctions': 'perceived_social_sanctions',\n",
    "    'performance_accomplishments': 'perceived_performance_accomplishments',\n",
    "    'vicarious_experience': 'perceived_vicarious_experience',\n",
    "    'verbal_persuasion': 'perceived_verbal_persuasion',\n",
    "    'emotional_arousal': 'perceived_emotional_arousal'\n",
    "}\n",
    "\n",
    "pme_renames = {\n",
    "    'PME_on_honest_task_completion': 'perceived_honesty',\n",
    "    'PME_on_task_performance': 'perceived_performance_effect',\n",
    "    'PME_on_task_experience': 'perceived_experience_effect'\n",
    "}\n",
    "\n",
    "df.rename(columns={**mechanism_renames, **pme_renames}, inplace=True)\n",
    "\n",
    "# Handle perceived ability\n",
    "if 'word_creation_skill_level' in df.columns:\n",
    "    df['perceived_ability'] = df.pop('word_creation_skill_level')\n",
    "\n",
    "# Define variables\n",
    "mechanisms = [\n",
    "    'autonomy_need_satisfaction', 'autonomy_need_frustration',\n",
    "    'competence_need_satisfaction', 'competence_need_frustration',\n",
    "    'relatedness_need_satisfaction', 'relatedness_need_frustration',\n",
    "    'cognitive_discomfort', 'moral_disengagement',\n",
    "    'perceived_descriptive_norms', 'perceived_injunctive_norms',\n",
    "    'perceived_group_identification', 'perceived_social_sanctions',\n",
    "    'perceived_performance_accomplishments', 'perceived_vicarious_experience',\n",
    "    'perceived_verbal_persuasion', 'perceived_emotional_arousal',\n",
    "    'perceived_honesty', 'perceived_performance_effect',\n",
    "    'perceived_experience_effect', 'perceived_ability'\n",
    "]\n",
    "\n",
    "actual_outcomes = ['cheating_behavior', 'performance', 'experience']\n",
    "continuous_vars = mechanisms + ['performance', 'experience']\n",
    "data_types = {\n",
    "    'ordinal': ['cheating_behavior'],\n",
    "    'categorical': ['concept'],\n",
    "    'continuous': continuous_vars\n",
    "}\n",
    "\n",
    "print(f\"Ordinal: {data_types['ordinal']}\\nCategorical: {data_types['categorical']}\\nContinuous: {len(continuous_vars)} variables\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3e8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. THEORETICAL FRAMEWORK MAPPING\n",
      "----------------------------------------\n",
      "Theoretical frameworks defined:\n",
      "  Self-Determination: 3 concepts, 6 mechanisms\n",
      "  Cognitive-Dissonance: 4 concepts, 2 mechanisms\n",
      "  Self-Efficacy: 4 concepts, 4 mechanisms\n",
      "  Social-Norms: 4 concepts, 4 mechanisms\n",
      "  Perceived-Effectiveness: 0 concepts, 3 mechanisms\n",
      "  Individual-Differences: 0 concepts, 1 mechanisms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. THEORETICAL FRAMEWORK MAPPING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"2. THEORETICAL FRAMEWORK MAPPING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define theoretical frameworks and their mechanisms\n",
    "theoretical_frameworks = {\n",
    "    'Self-Determination': {\n",
    "        'concepts': ['autonomy', 'competence', 'relatedness'],\n",
    "        'mechanisms': ['autonomy_need_satisfaction', 'autonomy_need_frustration',\n",
    "                      'competence_need_satisfaction', 'competence_need_frustration',\n",
    "                      'relatedness_need_satisfaction', 'relatedness_need_frustration']\n",
    "    },\n",
    "    'Cognitive-Dissonance': {\n",
    "        'concepts': ['self_concept', 'cognitive_inconsistency', 'dissonance_arousal', 'dissonance_reduction'],\n",
    "        'mechanisms': ['cognitive_discomfort', 'moral_disengagement']\n",
    "    },\n",
    "    'Self-Efficacy': {\n",
    "        'concepts': ['performance_accomplishments', 'vicarious_experience', 'verbal_persuasion', 'emotional_arousal'],\n",
    "        'mechanisms': ['perceived_performance_accomplishments', 'perceived_vicarious_experience', \n",
    "                      'perceived_verbal_persuasion', 'perceived_emotional_arousal']\n",
    "    },\n",
    "    'Social-Norms': {\n",
    "        'concepts': ['descriptive_norms', 'injunctive_norms', 'social_sanctions', 'reference_group_identification'],\n",
    "        'mechanisms': ['perceived_descriptive_norms', 'perceived_injunctive_norms', \n",
    "                      'perceived_group_identification', 'perceived_social_sanctions']\n",
    "    },\n",
    "    'Perceived-Effectiveness': {\n",
    "        'concepts': [],  # No direct concepts\n",
    "        'mechanisms': ['perceived_honesty', 'perceived_performance_effect', 'perceived_experience_effect']\n",
    "    },\n",
    "    'Individual-Differences': {\n",
    "        'concepts': [],\n",
    "        'mechanisms': ['perceived_ability']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create concept-to-theory and mechanism-to-theory mappings\n",
    "concept_to_theory = {}\n",
    "mechanism_to_theory = {}\n",
    "\n",
    "for theory, items in theoretical_frameworks.items():\n",
    "    for concept in items['concepts']:\n",
    "        concept_to_theory[concept] = theory\n",
    "    for mechanism in items['mechanisms']:\n",
    "        mechanism_to_theory[mechanism] = theory\n",
    "\n",
    "print(\"Theoretical frameworks defined:\")\n",
    "for theory, items in theoretical_frameworks.items():\n",
    "    print(f\"  {theory}: {len(items['concepts'])} concepts, {len(items['mechanisms'])} mechanisms\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76a426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. PARTIAL CORRELATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def partial_corr(df, var1, var2, controls=[]):\n",
    "    \"\"\"Compute partial correlation controlling for controls\"\"\"\n",
    "    vars_needed = [var1,var2]+controls\n",
    "    data = df[vars_needed].dropna()\n",
    "    if len(data)<10: return np.nan\n",
    "    X = StandardScaler().fit_transform(data[controls]) if controls else None\n",
    "    y1,y2 = StandardScaler().fit_transform(data[[var1,var2]]).T\n",
    "    if controls:\n",
    "        resid1 = y1 - LinearRegression().fit(X,y1).predict(X)\n",
    "        resid2 = y2 - LinearRegression().fit(X,y2).predict(X)\n",
    "        return np.corrcoef(resid1,resid2)[0,1] if len(np.unique(resid1))>1 and len(np.unique(resid2))>1 else np.nan\n",
    "    else:\n",
    "        return np.corrcoef(y1,y2)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f012084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. CREATING CONCEPT DUMMY VARIABLES\n",
      "----------------------------------------\n",
      "Created 15 concept dummy variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. CREATE CONCEPT DUMMY VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"3. CREATING CONCEPT DUMMY VARIABLES\\n\" + \"-\"*40)\n",
    "all_concepts = [c for d in theoretical_frameworks.values() for c in d['concepts'] if c in df['concept'].unique()]\n",
    "for c in all_concepts: df[f'concept_{c}'] = (df['concept']==c).astype(int)\n",
    "concept_dummies = [f'concept_{c}' for c in all_concepts]\n",
    "print(f\"Created {len(concept_dummies)} concept dummy variables\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac4b2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_edges(data, group_name=\"All\"):\n",
    "    print(f\"4. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS - {group_name.upper()}\\n\" + \"-\"*60)\n",
    "    available_mechs = [m for m in mechanisms if m in data.columns and not data[m].isna().all()]\n",
    "    available_outs = [o for o in actual_outcomes if o in data.columns and not data[o].isna().all()]\n",
    "    available_concepts = [c for c in concept_dummies if c in data.columns]\n",
    "    edges=[]\n",
    "    # Concept → Mechanism\n",
    "    for cd in available_concepts:\n",
    "        for m in available_mechs:\n",
    "            ctrl=[c for c in available_concepts if c!=cd]+available_outs\n",
    "            pc = partial_corr(data, cd, m, ctrl)\n",
    "            if not np.isnan(pc): edges.append({'source':cd.replace('concept_',''),'target':m,'partial_correlation':pc,'edge_type':'concept_to_mechanism','group':group_name})\n",
    "    # Mechanism ↔ Mechanism\n",
    "    for m1,m2 in combinations(available_mechs,2):\n",
    "        ctrl=available_concepts+available_outs\n",
    "        pc=partial_corr(data,m1,m2,ctrl)\n",
    "        if not np.isnan(pc): edges.append({'source':m1,'target':m2,'partial_correlation':pc,'edge_type':'mechanism_to_mechanism','group':group_name})\n",
    "    # Mechanism → Outcome\n",
    "    for m in available_mechs:\n",
    "        for o in available_outs:\n",
    "            if m==o: continue\n",
    "            ctrl=available_concepts+[oo for oo in available_outs if oo!=o]\n",
    "            pc=partial_corr(data,m,o,ctrl)\n",
    "            if not np.isnan(pc): edges.append({'source':m,'target':o,'partial_correlation':pc,'edge_type':'mechanism_to_outcome','group':group_name})\n",
    "    # Outcome ↔ Outcome\n",
    "    for o1,o2 in combinations(available_outs,2):\n",
    "        ctrl=available_concepts+available_mechs\n",
    "        pc=partial_corr(data,o1,o2,ctrl)\n",
    "        if not np.isnan(pc): edges.append({'source':o1,'target':o2,'partial_correlation':pc,'edge_type':'outcome_to_outcome','group':group_name})\n",
    "    print(f\"Total edges calculated: {len(edges)}\")\n",
    "    return pd.DataFrame(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0769e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS - ALL\n",
      "------------------------------------------------------------\n",
      "Total edges calculated: 553\n",
      "4. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS - NON_CHEATERS\n",
      "------------------------------------------------------------\n",
      "Total edges calculated: 531\n",
      "4. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS - PARTIAL_CHEATERS\n",
      "------------------------------------------------------------\n",
      "Total edges calculated: 531\n",
      "4. COMPREHENSIVE PARTIAL CORRELATION ANALYSIS - FULL_CHEATERS\n",
      "------------------------------------------------------------\n",
      "Total edges calculated: 531\n",
      "\n",
      "COMBINED RESULTS SUMMARY:\n",
      "Total edges: 2146\n",
      "Edges by type:\n",
      "edge_type               group           \n",
      "concept_to_mechanism    All                 300\n",
      "                        full_cheaters       300\n",
      "                        non_cheaters        300\n",
      "                        partial_cheaters    300\n",
      "mechanism_to_mechanism  All                 190\n",
      "                        full_cheaters       190\n",
      "                        non_cheaters        190\n",
      "                        partial_cheaters    190\n",
      "mechanism_to_outcome    All                  60\n",
      "                        full_cheaters        40\n",
      "                        non_cheaters         40\n",
      "                        partial_cheaters     40\n",
      "outcome_to_outcome      All                   3\n",
      "                        full_cheaters         1\n",
      "                        non_cheaters          1\n",
      "                        partial_cheaters      1\n",
      "dtype: int64\n",
      "\n",
      "Saved to: network_plot_partial_correlations.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. CALCULATE PARTIAL CORRELATIONS FOR ALL GROUPS\n",
    "# ============================================================================\n",
    "\n",
    "all_edges_df = compute_edges(df,\"All\")\n",
    "cheater_groups={'non_cheaters':0,'partial_cheaters':1,'full_cheaters':2}\n",
    "group_edges=[]\n",
    "for gname,val in cheater_groups.items():\n",
    "    grp=df[df['cheating_behavior']==val]\n",
    "    if len(grp)>20: group_edges.append(compute_edges(grp,gname))\n",
    "\n",
    "combined_edges = pd.concat([all_edges_df]+group_edges,ignore_index=True) if group_edges else all_edges_df\n",
    "print(f\"\\nCOMBINED RESULTS SUMMARY:\\nTotal edges: {len(combined_edges)}\\nEdges by type:\\n{combined_edges.groupby(['edge_type','group']).size()}\")\n",
    "combined_edges.to_csv('network_plot_partial_correlations.csv',index=False)\n",
    "print(f\"\\nSaved to: network_plot_partial_correlations.csv\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c07b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. RQ3.1: DO INTERVENTIONS ACTIVATE THEIR INTENDED MECHANISMS?\n",
      "======================================================================\n",
      "\n",
      "AUTONOMY CONCEPT:\n",
      "----------------------------------------\n",
      "  → autonomy_need_satisfaction: r = 0.025 ✗ weak\n",
      "  → autonomy_need_frustration: r = -0.014 ✗ weak\n",
      "\n",
      "COMPETENCE CONCEPT:\n",
      "----------------------------------------\n",
      "  → competence_need_satisfaction: r = 0.059 ✗ weak\n",
      "  → competence_need_frustration: r = -0.091 ✗ weak\n",
      "  Unexpected strong activations:\n",
      "    → perceived_emotional_arousal: r = 0.108\n",
      "\n",
      "RELATEDNESS CONCEPT:\n",
      "----------------------------------------\n",
      "  → relatedness_need_satisfaction: r = 0.020 ✗ weak\n",
      "  → relatedness_need_frustration: r = -0.010 ✗ weak\n",
      "\n",
      "SELF CONCEPT CONCEPT:\n",
      "----------------------------------------\n",
      "  → cognitive_discomfort: r = -0.055 ✗ weak\n",
      "\n",
      "COGNITIVE INCONSISTENCY CONCEPT:\n",
      "----------------------------------------\n",
      "  → cognitive_discomfort: r = 0.001 ✗ weak\n",
      "\n",
      "DISSONANCE AROUSAL CONCEPT:\n",
      "----------------------------------------\n",
      "  → cognitive_discomfort: r = 0.011 ✗ weak\n",
      "\n",
      "DISSONANCE REDUCTION CONCEPT:\n",
      "----------------------------------------\n",
      "  → cognitive_discomfort: r = -0.008 ✗ weak\n",
      "\n",
      "PERFORMANCE ACCOMPLISHMENTS CONCEPT:\n",
      "----------------------------------------\n",
      "  → performance_accomplishments: NO DATA\n",
      "  Unexpected strong activations:\n",
      "    → perceived_honesty: r = 0.116\n",
      "\n",
      "VICARIOUS EXPERIENCE CONCEPT:\n",
      "----------------------------------------\n",
      "  → vicarious_experience: NO DATA\n",
      "\n",
      "VERBAL PERSUASION CONCEPT:\n",
      "----------------------------------------\n",
      "  → verbal_persuasion: NO DATA\n",
      "  Unexpected strong activations:\n",
      "    → perceived_verbal_persuasion: r = 0.103\n",
      "\n",
      "EMOTIONAL AROUSAL CONCEPT:\n",
      "----------------------------------------\n",
      "  → emotional_arousal: NO DATA\n",
      "\n",
      "DESCRIPTIVE NORMS CONCEPT:\n",
      "----------------------------------------\n",
      "  → descriptive_norms: NO DATA\n",
      "\n",
      "INJUNCTIVE NORMS CONCEPT:\n",
      "----------------------------------------\n",
      "  → injunctive_norms: NO DATA\n",
      "\n",
      "SOCIAL SANCTIONS CONCEPT:\n",
      "----------------------------------------\n",
      "  → social_sanctions: NO DATA\n",
      "\n",
      "REFERENCE GROUP IDENTIFICATION CONCEPT:\n",
      "----------------------------------------\n",
      "  → reference_group_identification: NO DATA\n",
      "\n",
      "MECHANISM ACTIVATION SUMMARY:\n",
      "----------------------------------------\n",
      "activated             False\n",
      "theory                     \n",
      "Cognitive-Dissonance      4\n",
      "Self-Determination        6\n",
      "\n",
      "Overall activation rate: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. RQ3.1: DO INTERVENTIONS ACTIVATE THEIR INTENDED MECHANISMS?\n",
    "# ============================================================================\n",
    "\n",
    "print(\"5. RQ3.1: DO INTERVENTIONS ACTIVATE THEIR INTENDED MECHANISMS?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Focus on concept-to-mechanism edges for overall sample\n",
    "concept_mechanism_edges = all_edges_df[all_edges_df['edge_type'] == 'concept_to_mechanism'].copy()\n",
    "\n",
    "# Define expected relationships (corrected for cognitive dissonance)\n",
    "expected_relationships = {\n",
    "    # Self-Determination Theory\n",
    "    'autonomy': ['autonomy_need_satisfaction', 'autonomy_need_frustration'],\n",
    "    'competence': ['competence_need_satisfaction', 'competence_need_frustration'], \n",
    "    'relatedness': ['relatedness_need_satisfaction', 'relatedness_need_frustration'],\n",
    "    \n",
    "    # Cognitive Dissonance Theory - ONLY cognitive_discomfort as specified\n",
    "    'self_concept': ['cognitive_discomfort'],\n",
    "    'cognitive_inconsistency': ['cognitive_discomfort'],\n",
    "    'dissonance_arousal': ['cognitive_discomfort'], \n",
    "    'dissonance_reduction': ['cognitive_discomfort'],\n",
    "    \n",
    "    # Self-Efficacy Theory\n",
    "    'performance_accomplishments': ['performance_accomplishments'],\n",
    "    'vicarious_experience': ['vicarious_experience'],\n",
    "    'verbal_persuasion': ['verbal_persuasion'],\n",
    "    'emotional_arousal': ['emotional_arousal'],\n",
    "    \n",
    "    # Social Norms Theory\n",
    "    'descriptive_norms': ['descriptive_norms'],\n",
    "    'injunctive_norms': ['injunctive_norms'],\n",
    "    'social_sanctions': ['social_sanctions'],\n",
    "    'reference_group_identification': ['reference_group_identification']\n",
    "}\n",
    "\n",
    "# Analyze expected vs actual relationships\n",
    "mechanism_activation_results = []\n",
    "\n",
    "for concept, expected_mechanisms in expected_relationships.items():\n",
    "    concept_edges = concept_mechanism_edges[concept_mechanism_edges['source'] == concept]\n",
    "    \n",
    "    if len(concept_edges) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{concept.upper().replace('_', ' ')} CONCEPT:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check each expected mechanism\n",
    "    for mechanism in expected_mechanisms:\n",
    "        matching_edge = concept_edges[concept_edges['target'] == mechanism]\n",
    "        \n",
    "        if len(matching_edge) > 0:\n",
    "            pcorr = matching_edge.iloc[0]['partial_correlation']\n",
    "            activated = abs(pcorr) > 0.1  # Threshold for meaningful activation\n",
    "            \n",
    "            print(f\"  → {mechanism}: r = {pcorr:.3f} {'✓ ACTIVATED' if activated else '✗ weak'}\")\n",
    "            \n",
    "            mechanism_activation_results.append({\n",
    "                'concept': concept,\n",
    "                'theory': concept_to_theory.get(concept, 'Unknown'),\n",
    "                'mechanism': mechanism,\n",
    "                'partial_correlation': pcorr,\n",
    "                'activated': activated,\n",
    "                'expected': True\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  → {mechanism}: NO DATA\")\n",
    "    \n",
    "    # Show unexpected strong activations\n",
    "    unexpected_strong = concept_edges[\n",
    "        (~concept_edges['target'].isin(expected_mechanisms)) & \n",
    "        (concept_edges['partial_correlation'].abs() > 0.1)\n",
    "    ].sort_values('partial_correlation', key=abs, ascending=False)\n",
    "    \n",
    "    if len(unexpected_strong) > 0:\n",
    "        print(\"  Unexpected strong activations:\")\n",
    "        for _, edge in unexpected_strong.head(3).iterrows():\n",
    "            print(f\"    → {edge['target']}: r = {edge['partial_correlation']:.3f}\")\n",
    "\n",
    "# Save mechanism activation results\n",
    "activation_df = pd.DataFrame(mechanism_activation_results)\n",
    "if len(activation_df) > 0:\n",
    "    activation_df.to_csv('mechanism_activation_analysis.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nMECHANISM ACTIVATION SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    activation_summary = activation_df.groupby(['theory', 'activated']).size().unstack(fill_value=0)\n",
    "    print(activation_summary)\n",
    "    \n",
    "    overall_activation_rate = activation_df['activated'].mean()\n",
    "    print(f\"\\nOverall activation rate: {overall_activation_rate:.1%}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f058fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. RQ3.2: MECHANISM INTERCONNECTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_interconnections(edges_df, group=\"All\", show_top=10):\n",
    "    \"\"\"Analyze mechanism interconnections\"\"\"\n",
    "    mech_edges = edges_df[(edges_df['edge_type']=='mechanism_to_mechanism') & (edges_df['group']==group)]\n",
    "    \n",
    "    # Filter to theoretical mechanisms only\n",
    "    theory_mechs = sum([v['mechanisms'] for k,v in theoretical_frameworks.items() \n",
    "                       if k not in ['Perceived-Effectiveness','Individual-Differences']],[])\n",
    "    mech_edges = mech_edges[(mech_edges['source'].isin(theory_mechs)) & \n",
    "                           (mech_edges['target'].isin(theory_mechs))]\n",
    "    \n",
    "    # Classify connections\n",
    "    mech_edges['source_theory'] = mech_edges['source'].map(mechanism_to_theory)\n",
    "    mech_edges['target_theory'] = mech_edges['target'].map(mechanism_to_theory)\n",
    "    mech_edges['conn_type'] = mech_edges.apply(\n",
    "        lambda r: 'within' if r['source_theory']==r['target_theory'] else 'cross', axis=1)\n",
    "    \n",
    "    # Add absolute correlation column for sorting\n",
    "    mech_edges['abs_corr'] = mech_edges['partial_correlation'].abs()\n",
    "    \n",
    "    within = mech_edges[mech_edges['conn_type']=='within'].nlargest(show_top,'abs_corr')\n",
    "    cross = mech_edges[mech_edges['conn_type']=='cross'].nlargest(show_top,'abs_corr')\n",
    "    \n",
    "    return {'within':len(mech_edges[mech_edges['conn_type']=='within']),\n",
    "            'cross':len(mech_edges[mech_edges['conn_type']=='cross']),\n",
    "            'within_top':within,'cross_top':cross}\n",
    "\n",
    "print(\"6. RQ3.2: HOW DO THEORETICAL MECHANISMS INTERCONNECT?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall interconnection analysis\n",
    "overall_interconn = analyze_interconnections(combined_edges,\"All\")\n",
    "print(f\"Theoretical mechanism interconnections:\")\n",
    "print(f\"  Within-theory: {overall_interconn['within']} (avg |r|: {overall_interconn['within_top']['partial_correlation'].abs().mean():.3f})\")\n",
    "print(f\"  Cross-theory: {overall_interconn['cross']} (avg |r|: {overall_interconn['cross_top']['partial_correlation'].abs().mean():.3f})\")\n",
    "\n",
    "print(f\"\\nSTRONGEST WITHIN-THEORY CONNECTIONS:\")\n",
    "for _,e in overall_interconn['within_top'].iterrows():\n",
    "    print(f\"  {e['source']} ↔ {e['target']}: r={e['partial_correlation']:+.3f} ({e['source_theory']})\")\n",
    "\n",
    "print(f\"\\nSTRONGEST CROSS-THEORY CONNECTIONS:\")\n",
    "for _,e in overall_interconn['cross_top'].iterrows():\n",
    "    print(f\"  {e['source']} ({e['source_theory']}) ↔ {e['target']} ({e['target_theory']}): r={e['partial_correlation']:+.3f}\")\n",
    "\n",
    "# Group-wise interconnection analysis\n",
    "print(\"\\n8b. RQ3.2 BY CHEATER GROUP: DIFFERENTIAL INTERCONNECTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "group_interconn = {}\n",
    "for group in ['non_cheaters','partial_cheaters','full_cheaters']:\n",
    "    print(f\"\\n{group.replace('_',' ').upper()} INTERCONNECTIONS:\")\n",
    "    print(\"-\"*50)\n",
    "    group_interconn[group] = analyze_interconnections(combined_edges,group,5)\n",
    "    gi = group_interconn[group]\n",
    "    within_avg = gi['within_top']['partial_correlation'].abs().mean() if len(gi['within_top'])>0 else 0\n",
    "    cross_avg = gi['cross_top']['partial_correlation'].abs().mean() if len(gi['cross_top'])>0 else 0\n",
    "    print(f\"Within-theory: {gi['within']} (avg |r|: {within_avg:.3f})\")\n",
    "    print(f\"Cross-theory: {gi['cross']} (avg |r|: {cross_avg:.3f})\")\n",
    "    \n",
    "    cross_ratio = gi['cross']/(gi['within']+gi['cross']) if (gi['within']+gi['cross'])>0 else 0\n",
    "    print(f\"Cross-theory ratio: {cross_ratio:.1%}\")\n",
    "    \n",
    "    if len(gi['within_top'])>0:\n",
    "        print(\"Top within-theory:\")\n",
    "        for _,e in gi['within_top'].head(3).iterrows():\n",
    "            print(f\"  {e['source']} ↔ {e['target']}: r={e['partial_correlation']:+.3f}\")\n",
    "    \n",
    "    if len(gi['cross_top'])>0:\n",
    "        print(\"Top cross-theory:\")\n",
    "        for _,e in gi['cross_top'].head(3).iterrows():\n",
    "            print(f\"  {e['source']} ↔ {e['target']}: r={e['partial_correlation']:+.3f}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 9. RQ3.3: OUTCOME PREDICTORS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_predictors(edges_df, group=\"All\", show_top=8):\n",
    "    \"\"\"Analyze mechanism-outcome predictors\"\"\"\n",
    "    mech_out = edges_df[(edges_df['edge_type']=='mechanism_to_outcome') & \n",
    "                       (edges_df['group']==group) & \n",
    "                       (edges_df['target'].isin(['cheating_behavior','performance','experience']))]\n",
    "    \n",
    "    predictors = {}\n",
    "    for outcome in ['cheating_behavior','performance','experience']:\n",
    "        out_edges = mech_out[mech_out['target']==outcome]\n",
    "        if len(out_edges)>0:\n",
    "            out_edges['abs_corr'] = out_edges['partial_correlation'].abs()\n",
    "            top_pred = out_edges.nlargest(show_top,'abs_corr')\n",
    "            predictors[outcome] = top_pred\n",
    "    return predictors\n",
    "\n",
    "print(\"7. RQ3.3: WHICH MECHANISMS MOST STRONGLY PREDICT OUTCOMES?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall predictor analysis\n",
    "overall_pred = analyze_predictors(combined_edges,\"All\")\n",
    "print(\"Mechanism → Actual Outcome relationships:\")\n",
    "for outcome,preds in overall_pred.items():\n",
    "    if len(preds)>0:\n",
    "        avg_pred_strength = preds['partial_correlation'].abs().mean()\n",
    "        print(f\"\\nSTRONGEST PREDICTORS OF {outcome.upper()} (avg |r|: {avg_pred_strength:.3f}):\")\n",
    "        for _,e in preds.iterrows():\n",
    "            theory = mechanism_to_theory.get(e['source'],'Unknown')\n",
    "            print(f\"  {e['source']}: r={e['partial_correlation']:+.3f} ({theory})\")\n",
    "\n",
    "# Group-wise predictor analysis\n",
    "print(\"\\n9b. RQ3.3 BY CHEATER GROUP: DIFFERENTIAL PREDICTORS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "group_pred = {}\n",
    "for group in ['non_cheaters','partial_cheaters','full_cheaters']:\n",
    "    print(f\"\\n{group.replace('_',' ').upper()} PREDICTORS:\")\n",
    "    print(\"-\"*50)\n",
    "    group_pred[group] = analyze_predictors(combined_edges,group,5)\n",
    "    \n",
    "    for outcome,preds in group_pred[group].items():\n",
    "        if len(preds)>0:\n",
    "            avg_strength = preds['partial_correlation'].abs().mean()\n",
    "            print(f\"\\n{outcome.upper()} predictors (avg |r|: {avg_strength:.3f}):\")\n",
    "            for _,e in preds.head(3).iterrows():\n",
    "                theory = mechanism_to_theory.get(e['source'],'Unknown')\n",
    "                print(f\"  {e['source']}: r={e['partial_correlation']:+.3f} ({theory})\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f254e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 10. RQ3.4: PERCEIVED-ACTUAL ALIGNMENT\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_alignment(edges_df, group=\"All\"):\n",
    "    \"\"\"Analyze perceived-actual outcome alignment\"\"\"\n",
    "    perceived_vars = ['perceived_honesty','perceived_performance_effect','perceived_experience_effect']\n",
    "    actual_vars = ['cheating_behavior','performance','experience']\n",
    "    \n",
    "    alignments = []\n",
    "    for perc in perceived_vars:\n",
    "        for act in actual_vars:\n",
    "            # Look for direct edges between perceived and actual\n",
    "            align_edges = edges_df[(edges_df['group']==group) & \n",
    "                                  (edges_df['source']==perc) & \n",
    "                                  (edges_df['target']==act)]\n",
    "            if len(align_edges)>0:\n",
    "                corr = align_edges.iloc[0]['partial_correlation']\n",
    "                alignments.append({'perceived':perc,'actual':act,'correlation':corr})\n",
    "                print(f\"  {perc} → {act}: r={corr:.3f}\")\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "print(\"8. RQ3.4: DO PERCEIVED OUTCOMES ALIGN WITH ACTUAL OUTCOMES?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall alignment analysis\n",
    "print(\"Perceived vs Actual Outcome Correlations:\")\n",
    "overall_align = analyze_alignment(combined_edges,\"All\")\n",
    "if overall_align:\n",
    "    overall_avg_align = np.mean([abs(a['correlation']) for a in overall_align])\n",
    "    print(f\"Overall average perceived-actual alignment: {overall_avg_align:.3f}\")\n",
    "else:\n",
    "    print(\"No perceived-actual alignment edges found\")\n",
    "\n",
    "# Group-wise alignment analysis  \n",
    "print(\"\\n10b. RQ3.4 BY CHEATER GROUP: ALIGNMENT DIFFERENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "group_align = {}\n",
    "for group in ['non_cheaters','partial_cheaters','full_cheaters']:\n",
    "    print(f\"\\n{group.replace('_',' ').upper()} ALIGNMENT:\")\n",
    "    print(\"-\"*45)\n",
    "    group_align[group] = analyze_alignment(combined_edges,group)\n",
    "    \n",
    "    if group_align[group]:\n",
    "        avg_align = np.mean([abs(a['correlation']) for a in group_align[group]])\n",
    "        print(f\"Average alignment: {avg_align:.3f}\")\n",
    "    else:\n",
    "        print(\"No alignment edges found\")\n",
    "\n",
    "print(f\"\\nALIGNMENT COMPARISON:\")\n",
    "print(\"-\"*40)\n",
    "for group,aligns in group_align.items():\n",
    "    if aligns:\n",
    "        avg = np.mean([abs(a['correlation']) for a in aligns])\n",
    "        print(f\"{group.replace('_',' ').title()}: {avg:.3f}\")\n",
    "    else:\n",
    "        print(f\"{group.replace('_',' ').title()}: No data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RQ3 ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheating_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
